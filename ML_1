# Step 1: Import libraries and load the data
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from scipy.stats import zscore

# Load dataset (assume file is 'uber_data.csv')
data = pd.read_csv('uber_data.csv')

# Step 2: Pre-process the data
# Handle missing values
data.fillna(method='ffill', inplace=True)

# Create new features from timestamp (if available)
data['hour'] = pd.to_datetime(data['timestamp']).dt.hour

# Step 3: Identify outliers using Z-score
z_scores = np.abs(zscore(data[['distance', 'duration', 'fare']]))
outliers = (z_scores > 3).any(axis=1)
data = data[~outliers]  # Remove outliers

# Step 4: Check correlations
correlation_matrix = data.corr()
sns.heatmap(correlation_matrix, annot=True)

# Step 5: Prepare the features and target variable
X = data[['distance', 'duration', 'hour']]  # Assuming these are relevant features
y = data['fare']

# Step 6: Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 7: Implement Linear Regression
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Step 8: Implement Random Forest Regression
rf_model = RandomForestRegressor(n_estimators=100)
rf_model.fit(X_train, y_train)

# Step 9: Evaluate models
y_pred_lr = lr_model.predict(X_test)
y_pred_rf = rf_model.predict(X_test)

# Calculate R2 and RMSE for both models
r2_lr = r2_score(y_test, y_pred_lr)
r2_rf = r2_score(y_test, y_pred_rf)

rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))

# Display results
print(f"Linear Regression R²: {r2_lr}, RMSE: {rmse_lr}")
print(f"Random Forest R²: {r2_rf}, RMSE: {rmse_rf}")
